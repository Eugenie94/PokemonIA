{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\eugen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\eugen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\eugen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\eugen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\eugen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\eugen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\eugen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (20.9)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\eugen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\eugen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\eugen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\eugen\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of images array: (819, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Chemin vers le dossier contenant les images de Pokémon\n",
    "pokemon_dir = \"./pokemon/pokemon\"\n",
    "\n",
    "# Charger toutes les images du répertoire\n",
    "image_files = os.listdir(pokemon_dir)\n",
    "\n",
    "# Lister les images par ordre alphabétique\n",
    "image_files.sort()\n",
    "\n",
    "# Créer une liste pour stocker les images\n",
    "images = []\n",
    "\n",
    "# Charger chaque image et l'ajouter à la liste\n",
    "for file_name in image_files:\n",
    "    # Ignorer les fichiers cachés\n",
    "    if file_name.startswith('.'):\n",
    "        continue\n",
    "    # Charger l'image\n",
    "    image_path = os.path.join(pokemon_dir, file_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    # Redimensionner l'image à la taille spécifiée (64x64 pixels)\n",
    "    image = cv2.resize(image, (64, 64))\n",
    "    # Normaliser les valeurs de pixel entre -1 et 1\n",
    "    image = (image - 127.5) / 127.5\n",
    "    # Ajouter l'image à la liste\n",
    "    images.append(image)\n",
    "\n",
    "# Convertir la liste d'images en un tableau numpy\n",
    "images = np.array(images)\n",
    "\n",
    "# Vérifier la forme du tableau d'images\n",
    "print(\"Shape of images array:\", images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAndklEQVR4nO3df7RdZX3n8e/dHI+XyzVekR8xQX6FHwLSEAExA5ZStBbR5Wod1EEZpZiVRnBKx6pjXZ2O7WJmWcdlO0izmEykSrW1IJRhMYXOqEUHqUUnBkQQQgwJhBjD5XA5uRyOO/vOH3E9s6bP5xPOQ841N9f368/v3XnOPvuce7/nrP3J9xmZmZmZCQAAIqLa1ycAAJg7aAoAgISmAABIaAoAgISmAABIaAoAgISmAABIaAoAgKQ16IEjIyOzeR4AgFk2yP9V5psCACChKQAAEpoCACChKQAAEpoCACChKQAAEpoCACChKQAAEpoCACChKQAAEpoCACChKQAAEpoCACChKQAAEpoCACChKQAAkoE32QGAfWn5J5fI+t1/+4j+B3fv/WMe+jFd/8l/2vu15yq+KQAAEpoCACChKQAAEpoCACChKQAAEtJHAPYL27pb9Q9OMP9ApY/O1oee/o7Fsv7d33n8ec9rvuGbAgAgoSkAABKaAgAgoSkAABKaAgAgIX0EYE5Z8gcHyno1YT7Dbh587fPfd4qsf+uh+wdfZJ7jmwIAIKEpAAASmgIAIKEpAAASmgIAICF9BGDWLfl4nihqmkYeW40XLr5Rl0+6+tCstrm7SR77bKfwMZebuvqYfVfh2vsY3xQAAAlNAQCQ0BQAAAlNAQCQcKMZeB7H/G5+wzIi4uTTTs5q3c42eWy3Oy3rvcrU1fHmI1x7bFTWG/fbbW7wqhu/Ta/Wx1b6ZCq9dDRNvk7VNufX1ms//I2dsn7Umw+S9brXy2uhn09MmXNxN5TzpXdbZ+r7Eb4pAAASmgIAIKEpAAASmgIAIKEpAAAS0keYt9503evNT0wCxSRqWubXpBEJodFGJ4Emm0lZ75sYSyMSOFWtoz39nk4wuY98JnwUlfoH7lK1zCL2+Ly2Y8dz8tin/1DXT/yzl+nFjabp57Upc4IuTZQvsZtLTs0DfFMAACQ0BQBAQlMAACQ0BQBAQlMAACSkj7BfOekzi2X9yIOPy2ruzV2FmRVkjq87HVnvTO/IajtELSKiWqDjKk1Hp2EqdYqyGOEjMpr9JNjkP9m0Uc8bOvbVet5Q03bRpnztw47Waxz2aXeGhXEqURYjmHa7xdTPNPXSjYD2I3xTAAAkNAUAQEJTAAAkNAUAQEJTAAAkpI+wT534Sb2rmdvCa4FJ4ExNPpbVxswcIrXDWEREv9Ypnm397bIe/fz4atz9SpnYi5mh0xLP84efeNqsbZyoy8t/6yhZ74nLcvKr9DXsN25YkKZ2ajOjpqL0z1Jj0leNeEJNf1fR2vZjs9upbR7gmwIAIKEpAAASmgIAIKEpAAASmgIAICF9hJ+fi/JSPdWVh7pkyo7KpF5a+Vu57XZMm9Y7ldXmt0HtGhYR0Uzk0SF3rDq/iIiHP6xnC510VZ76Of/qpfr8apNsciOBTLKrLXZ222pmObk5Ue55RlfsgtY20Svz2hd/ghWXRQTG9sw9UTeGah7gmwIAIKEpAAASmgIAIKEpAAASbjRj+N5k6uIjiLvpqTZ8iYiIMbN0K1+nrvRdxWpc3+CszPiLqjI3ROv8pveGB/WN413f0Usc/2m90cwREydktaajb7I37lq19A3o2tw93drLR4U04rrufkxzrdy5iJvKTddsMNQvO28/LyM/vjesG806HzEv8E0BAJDQFAAACU0BAJDQFAAACU0BAJCQPsLw6ckIofZCaY4zCZS22SBn2sRBRErGhVKaMfdZSKeMmtCpn4dV0ugbeuUlFx+o1zYJnMnIk0B1Rx87Pr5A1ndM682BapP4arXVddHXyiW1mq6L64hzd6+PG3PhRmi03XySfKHetuf0sY5Ju5l9feYFvikAABKaAgAgoSkAABKaAgAgoSkAAJJ5nz666oZzZb3bm5T16b5ObEz3p/KiaalrVj470Lnt984ydTMqSF2vqWaXPPSQlr64jdgIJiJ0sqmtoyNVR0dHRhfq4++7/Cn9mMKBS3T9Xa8+Vtavuuh+WT/+U3lap2nrFFR32mw85GY/mRSPurKVTCRF1FM6CWWTQ3LwlXktR/UirfFxfbzRn8p/Z39qLpXl/kLqfZrmBb4pAAASmgIAIKEpAAASmgIAIKEpAACSkZmZmZmBDhwZme1z2SvLLtL1N7xFx0HqWscHuo1IGYXeaarV0vN5rr1s8LRKRMTZl+S1t1z8dnlsv6e3fGrUbJndP5DqJk+m9Ewiq9fXw4zao/r53/i5R2V9y1f1uZR45Uf1TmUTC/L5P/d99gm9iCl/8pY3ynrTNyme0YOz2uTURnlsp7dV1rdu+4msb1jwiqzW39aRx4Z5HRqxM1yETx9VYiZUPWnW0GcSUZm4jkoamYRZa0KnjNxj1iZ9tWP701ntqU1mEf1r77kRT+qtcnfh2rNokD/3fFMAACQ0BQBAQlMAACQ0BQBAMm9uNK9a81JZVzdUI8LvwGL65JoVz2S1T9x8gTx23IxXsDNFKnWjUJ+Hu2GpboTvXsbtZJKX6lpfq655zJ692+aI0Q3mJnaYcRbuaa79/XzzlKs+d7481r3yLXHjOCJiut+R9e2dH2S1fq2DAO5Rt27WoYTb/jivLfm43qgn2mauSOl7X11zk19wo0xK3oatCb05kJ2VYZ5PZ/uTsr5dvLVmHtRL28103Jul5K0/hIDFsHCjGQBQhKYAAEhoCgCAhKYAAEhoCgCAZN5sslM3+r+6u1ROqzUh6wsPeY2sf+aOhVmtMtGMpu9GURhNPnKjMiM0iuIdEVGZl7ipxDriPCIixkcPkfW2GRUyZdI6eiccc2hLx1uOWHCyrF/1OTEawVyTafOgnc73Zb3X0xsvhXnPzRr322rfEybB5UJJ6nAx+iIibCqpMo/ZWqBGV5Rt1LNjq04ZTXX08TOq7jaAMtckvmnqeu8unWK60Bx7m6nvY3xTAAAkNAUAQEJTAAAkNAUAQEJTAAAk+2X6aMW1L8mLJlJRNXlqKCLiiENOk/WJ8UWyrjYsaeycG8POUckTG415PgvG9PPp9vUuIV/6rzri8MAsJh9ecqauv+u3841j3DVpm5jI9qmHzD8Qc3QqvYZ7Gfp9vclQlMwzsjO1NBccWvrWvNY1m9K4OVFRm+NduZ3/oHFrmORQa4EeIlRX+fHdKX1dO5M/lfXn3MtgXrbYZuqKm/HkuHNRL8Vh5ti3mfothecyZHxTAAAkNAUAQEJTAAAkNAUAQEJTAAAk+2X6qDeV74J201/qYz/yR78k6wvGTCTAjhZSW0epeS4RjUkClfTg22/637J+x9ofy/oBy/U6u8zGZiGCQOFG+einGbFFly/+wGJZr1W6x8Rv+pWOd7RHTTqsyt/Kbu5VbXZ7a8wsJ6dqqV8f/Rq7NJmd/STqLTMPqu6Z85bnF9Ea1edYT6tz1CfY6+mE0HT3WX28GrVlnvtP3XvW/Vq549XTdy+xex1ON/XvmvpZotYxx7o5TPsY3xQAAAlNAQCQ0BQAAAlNAQCQ0BQAAMnIzMzMzEAHjozM9rnslQ/9lY4JLBjTaZUFZjcxl/CQ/dPsvFWbFMuG7/9A1q/58H1ZbUSlGCJixiWEXDKjZDyTGB8UEREbdfnyL5wo6/3prfofyN3ezE5dLmWkV5Yjh2q3Y5qYY7V7ERPGc/OM1PFuDJHZ1W7bRp3i2SreKutv1Wsf/lHzmOZp9k2aTIWy3FilXW6nMvf+VHX3kbRj6iXzhiJ0+sjNOLK72pn6Paau/gzpPzX+Md21/Z+mXmCQP/d8UwAAJDQFAEBCUwAAJDQFAECyX465WHX98Vmt3XazGMx/03ejKGp9SdS9xl5f3/n6w7fpHWxGzOYz6ubUjNs4xN1QHjV1d6NsQtQe0Yde/sUh3FAOPXbCj62wOxLJat3riKK5Y2fDBGZTnpKNc1rmhejrO5x1o28029dN+LEb8+BuWLpRD+pmcKfg2BfymErpR9WSfYDcsaW/P+eauroubg13rfbxR3W+KQAAEpoCACChKQAAEpoCACChKQAAkjmdPlp1/ZKBj+2pDVwiYqylZzfUbtMTEwlo1P/3N2t88OqjZP3qP31UP6QKMbn/ju9CVi4N4oI2Imm08jq9OU6vu1nWfSrHjK5oHyyO1GtUNmXkojbieDO2ompNmDXKno883jxmr6/jN6Zc9nFtg6m798TYEB6zIB1l13bv8VLuvFXd/cVzvyfuebpz/7aoXVC4tqPSi27cxl7gmwIAIKEpAAASmgIAIKEpAAASmgIAIJkT6aPLxSyjiIjabMBSidk6VaWHlzTmFn9l+qGaz7O7nkc5+l0z+2dMR0rOPEcffs9Nag19rE2U/FiXL/i4ri868sVZzW1K41JGNjlUmZMX61Q27eWeqIlsiNe/aruBNkNIGe2xnuvXenOTnkkfqbfz2Sv0sXfdax50GL/d7pKUJmfUW6L0crukVsk67tiOqbtrWPJx2r0NHReMzMN7s4JvCgCAhKYAAEhoCgCAhKYAAEhoCgCAZE6kj8ZHD5P10ZYe9LO9mw976fb07KNptSNXRIy29Uyk22/8rqw/8JW8tmLNQfLYxuz4ddo5L5P1X/oXedJm7cpn5bGnv1eW4zXnvESfS2OGtMh6WRzEZnLcTKQmr4vSnrlEWlvEW8yxbnBNaVJNrmF2nXObwLm6msUz7dI3at5OhN8drGSnMr25oOf+oqjL4l4eN9/LzRsq+StWOm+p9DHVfCJ3DfWfIJ9WcrsuDhnfFAAACU0BAJDQFAAACU0BAJDQFAAAyc81ffTB60+U9b/587tk/YqTL5L17a8TKRa3k5pJwvTqjqyrlJHj5vPYnb3MY0aVR01cssn2cZsyMtdF7Uhn1mgaHXupzNvnsc16d7Qjjz46q9W1jmY0/Y5+TDeHqZ/PbWq19LCYYaSMfnYyWanu6+djysUjhJSDlun6zjvNP3CpJHWObkcyl8opeULucruUjUsluXXU85ntsVcqOVSSyNpTXb0WF5pjbzP1AfBNAQCQ0BQAAAlNAQCQ0BQAAMnP9UbzP/39Q7L+jd//oqz/m//872X95mseyWorP79EHvulz+bHRkRc/IHFsl7EbCZT1/pOWUvcUI7QN0/dzeqq0i+Z2xwo+vqmr/w80NLn15idYNoLjpD1E45zdydzU9Ob9Q/M81mzSm9Wo11s6p+S1ZXXvVIfbm5uqxvT0+aO8nTpuAjx9F1mYOc6XX/97+j6N//MPOZZouZuKLuX2P1FUW+h0o+kpTe3SzbZcc+ntK7Wd8/T7SPlrqEbiTJkfFMAACQ0BQBAQlMAACQ0BQBAQlMAACSzlj5add0rstoZG98ijz34tW+W9ZvvuNes/smsUplYgQvlNGa8wov0JI543++9WKyh4wMtkxAKU6/ah+Q1069XX6HTVCv/y1Gybsd/qPMw16o9frSsX3PlD2X9E/9N/9/7yamN6lHlsWsv3yXrj3/9BllffN5fi6qLq+hYzrWX6liOS7apcRn9/nPy2OmOPpPG1NVlqdzmK0bXBM/OvlzX77pGFFUiKcJf2pKETGkSqHSDHPXWKk0TDWMsRmn6aBijQvYC3xQAAAlNAQCQ0BQAAAlNAQCQ0BQAAMmspY9WX/FEVtu59U/ksQsXvUzWD4iPybrKpTQmmnDGOfr8otG3/t935YvM8Wo+kZtlZGIiLT0rSb0Mq9/7sD70pWaFalLWXWCjErGsakzPMtr40FZZdykjpy8261m76qfy2C13/52sL15+gayr94rOL0XoQTwRNpX0Xp1KunTNy7OaS/z0t5mHdEE1lUAZfKTUHnXNuSx7e15b5zadOt3Uh/Ex071p3a9PyUY4pX/xSndBUse7t5tTmrIaMr4pAAASmgIAIKEpAAASmgIAIKEpAACS2dt5bWdeGlswIQ99Zmc+Vygi4gCz9AHqB2aW0cEHm0XcfCITN6jabqGStXX9WpU00oGsiI4u17XZHcwkoVqj+bwlF7S446pnZf2cW/Rj7uhukvXtW/NozuP33yOPXXTyGeZs8sSPp5/RzMyfyvrIyJVmHT0Qa6qTz36afsws4d4SLmlS8HZb9m5dt2N7zGOq+lId9or1OhxWPitJcSfurmHJR9vSNNEwZh+VPuYwHPjC/ynfFAAACU0BAJDQFAAACU0BAJDs9Y3mVde9Utb//H2bC1a5QlZ3mZ51YDsfReE2k5k4zI2t0GV7Q1nePC67g3Tte/UGOaEu4ZRZZKEuN+alrNrj5vjBq8su04853dcn2TObD236Qn7Te+FHXqMXt94/8JEfu/wNhWu7X4dfl9Vv3JjfaD7SvD7uRms18bwn9bzsPWy34Y270Sx+3e67zawxYurfNvXlg5/HUG7ulird8KZkg6AhjScporMhA+GbAgAgoSkAABKaAgAgoSkAABKaAgAg2ev0UTWUtqJv5b/t7NfJ+j/cm592ZUZLtNpuI5yySEBb9E8X7ii+rGrzEHddH9XlqnI7kOz9/7H/5V89RdY7PT3T4R+/plNW3/nec1mtKn4D6ZjILhHxeP+VZcmmc099razfed+3ZP0nImlzhNl3qFpQdCr6ZTMvpZ0gUZicsUkjZabg2IiIu0XNBAPjNFMvTR+pC6On4Xhu7YdM/eSCNYYx/mIWRmjwTQEAkNAUAAAJTQEAkNAUAAAJTQEAkOx1+mjjQ1uHcR5F+mKoSyMjPBFhUkaVmxVk0jB9GWUoixWs/Pwx5vh8HTsnqZTd8Eecu9l9pZnWr3Hd6CjH+s/rR2z9xTCGwLi4Rf6e+D//mG/qExFx7HF6vtWd9214oSf1/+hRU+Ufv9TTLEyxuJdezTiKiFj21ry27lbzmKXUxlgukaX3XYo4t/AxS5NGipvldLqpq7f4bG7sM1249l48PADgFxBNAQCQ0BQAAAlNAQCQ0BQAAMlep48mDnEzd0ro7aoevFfPuWmP7cqLJjkz1tIRh7apV6ZPTtV5kqUp7Kku2aRCBas+v8Ssop9nXetd0KrIdzuLiGjqPLbQ1Dqu0Zhr1ZgYy4jblWsoXIIpvy4XXXKTPHLmPf/OrLHN1N3rvFQcur5sCUe8KRqXMjJrVyaZUpl1zK/QcIhf2XjSHPtSU7/T1N37Tb313Y5kZ5v6WaZeModpWLOP1LA1P4DtBeObAgAgoSkAABKaAgAgoSkAABKaAgAg2ev00fiYTgiV0bGHHz4z+Nquu7VbOh01Njoh69O9jqzrpFFZfMCmR8TaTaOfu5tDFC2TMjIXpqnV+u7toF+fqq2v7R/9x9826wyDO0d1cfV5nzyhU0l62yy/TsSr8lK1yhxrFCSB7CZ1ZsZP3x1fcAmXX6QPvfsGs8YwuJlFB5q6SxSpuksZlf4Z079u2izsjjab+KYAAEhoCgCAhKYAAEhoCgCAZOAbzcvd/bNK32y84i8WZbVrLn1i0If7mesHPnJ09DBdb+sNVVw/rBv3/8bF3SIxKmL30m4Ug3vM/C5X0++YJfQaVaXvfFXmRrv6//GN2Lwowo/zqMyd83/9ng+YxxyGT5r6alHTO9488LS7k+l2yHE+l5cG3wNo9+HuBqcac+HGWQzrRqZYf3oWNnF5XmokRoS/oezGXMyI2l3mWLdpjvv1cR+nS/Ioru7eE+o9NAujSfimAABIaAoAgISmAABIaAoAgISmAABIBk4fjblxCSaB0u/lm9J87PqT5LFVpU/jqndfIuufuPmNWa3X267Pz6R42u0JWe+bzWrqfr5+ZVJGTaMjGy2TEHKpH7nGWJ7q2n0u7v/du4iDSGU1k3oFl7IyNm3YLOtHHnFC0TplSpJD7li3+c7DsnrWpXmtby5V4wJPJUE1kzQp2e8lIqIpSNS4dNSyt+n6uv9u1lZJoGEpWHupOe/1t5h/8HpTL0mZDWMzHcfs6bQ3+KYAAEhoCgCAhKYAAEhoCgCAhKYAAEhGZmZmBrp3PzLiBoxol16TH3/w+NHy2NGWToNUpt6o+UQmJjHaXqDXNsGrx7obZb3u52mqMKmpcEkgt0uKSHC1WhP6UL1CVGZtlw7TB+uITFO76Iy2ZsXOgY9d8YmXy/rXbn9S1h+5W69z+Hl57c3vepE8tjv5U1mvTbpnUgfbYlqEtfo6vFYcEVIvW/GMI5Nscm9PtbFP6Wwdm+KZI5ZeYH5grpV9Pm6zHvV6uo/e7tq69NE9pl5gkD/3fFMAACQ0BQBAQlMAACQ0BQBAQlMAACR7nT5a+hv6+PU357U3mt3bFh6t64sWHS/rKjlUtUykoq8TQuOHHCnrm3d8T9YbERWws2VM4sfNeFKppNqtUbTlU0TlIitqI7neVrO2e0iTeHKznNTxJvJTtXQcxM6bqvP0mbvenY5OR02ap98zKZFvfimvLT1HH2u5BErBDl7NwBPMfrZ0SRLKvsnLHnP9rWXHz5ZTL9T10k/H628zP3CpJMVdQ5OwGwbSRwCAIjQFAEBCUwAAJDQFAEAya2MuloobOu4+6zrzX8nPXanr42L6xRHHHiSP/Yev6ZuK73jP+bK+o6s3iNE3j/Wdoi989keyfsZrZTle9dqjslrL3FAtnZcgR4JERN3blq/gXqBC7kazHsVhbpCb4EDd0yM3up18dMWUGU/RMxvhPLRB1x//uq6rm5ZFN3H3VFc3oN3L4x6z9FzUEm5UhrlBbpcW525Pz/2gZB+liKjE27DumIPdtTVPaP3fm+P1BBXtFab+RMEahbjRDAAoQlMAACQ0BQBAQlMAACQ0BQBAMmvpI8VtcFFN6HrLtKx7vjj4Y573IV0fNUmGicN0imlsbCKrtWxaxySBTN5Cb/hTuLuJ3CEloumLnWBCj+2QO7tERLjREub4un5O1lVwqG/27+mJPY325A4xciKeKVvj9Lfrursscl+n0g1VxnRZjYlRib4Xwgah1Lm4TYBKxnOEThqVTtCwv27mPSTPUe+5FZVZw+6LZV63dV/W9bmC9BEAoAhNAQCQ0BQAAAlNAQCQ0BQAAMnPNX1kHajLy35T17c9lteeuHN4pyMtyUsXXKwPnZ7SdbsvifhB6diaUZOGaEyqYns++iju+4pZfB84NF4p63XouUo3rrkyq52/4mPyWJeCc5vV2Fk8BVzCrm1mC234Xl47YpFZwyTpWu75FJxLV4fX3N5IRXOYXKrLJrVKZzyJdcYO0YdOLNT1HeJvTUREbeZnqb2h7rlBH7svkD4CABShKQAAEpoCACChKQAAEpoCACCZG+mjQsvePfix68ycpJPiTFmfio6sq+7pE0K617ZD7yZWiXrbbAXl5ie5s/FH5ykel+xx9VIlIR73aWVLPCzrp75VrFE4PqrSL48fCaWOL9xhzb0/z7wkr6kdByMixg7W9SNOOEbWp6d1pKjbeTqrTZn0UdfMpjKb7sk5RG5+kkt7ucTTmEneHS12Ohwfe7E8dts2Pa9r+4N67b5JHynrbx382NlG+ggAUISmAABIaAoAgISmAABIaAoAgGS/TB+VWPZO8wOTcFhn5pScEudltVcffpo8dnRcxyEqs42TShS5BFO5wTM/LmUz3dUDlHb8WAxQiojtoQfGTEUeZdkSD8hjTzLzicyoIMnu1GV23xqGHdt1/bENuv4r/1LXFx2dDwQbF7v/7Uklt1LzenX+Ok93O/LYzQ/qtM7dq/Xay/6VKJo0kdtxcau5tm++2AxPK/gd2rp5p64/pI9vTPpIvefc+/C7+2AmEukjAEARmgIAIKEpAAASmgIAIHG34uaNdV/W9fM/pOunmxEadffrWe3Lt+S1iIj48Utl+b3HXyHrQ7mp7JZoBl/b3AeP8QX6zuz4hK5//YfmogvLCje8cTcnK3UH2oyFKDVqxl/cvTavnbVCH3vGr+n6wsPE7k0R0fTzm/JNv6MXabs75/piVebXvt0SF2xMr9Fq6xvNlggxuLEVXTMq480XH6SXNgu1R/M3xepL81EeERFv0vsx+Q1/zHuiaB7OHMU3BQBAQlMAACQ0BQBAQlMAACQ0BQBAMu/HXKxcoxMLldnJY/Vlz8r6uavyWq+jH7M3petjJiRy91/peolXxFJZfyLW7/3ixlKxsU1E2FkUjUiV2I1wzMcVO7mhYP7FJjO64Kl7dH3Jcl2fOC6vvfqXD5XHjpmEUN03sxtKIisqNRQRlYxk+boy2dkk61s37JL1h76n11koNgJaf7M+dsW1JmVkokBrV5oklAp2md/NC96v69vMJjvuEsqNg8xIjB0mZbXlq7o+DIy5AAAUoSkAABKaAgAgoSkAABKaAgAgmffpoxWrX1x0fKtlhu601ByVp4rWPtvMVeqqdIJJJrgNO+ysILOOCnI0JlFR9cwa7viSZIZJH42KtEpExLevN+ciHHO6rrvA05bvDr52RMSK616Z1WyyR2xgExHRmN1aKvFCN+YzXFW5QTyGTR/l6z/22CPyyCm9j1L0zfvt22JO1GWrX6TPwgzhWuNSRsfrskwamffy4tN0/RA3VsqFw0TdXe62edm+PfjosGKkjwAARWgKAICEpgAASGgKAICEpgAASOb9zms+a6L7oT26zmMVl5kZLRsf3CnrXTN3pbMtrz06i/NP5pKTztX1SXFNIiIWu6SJeDn7OvDj5ycZJ16k6y2RSGtkxCqicYmay57Ri6vklElHrVz7cv2YJiLTMhG2vhhONd3Rj+l+T1TKKCJi6SV5TSWsIiLWrNTzx+JU86AuHadO0vwOPn6nrh9yoVnbEZdczfyKiOgVzOv6eeKbAgAgoSkAABKaAgAgoSkAAJJ5f6O51dJ3Fd1NOP+/1/NLtXbl00Xn8voP6vqRJ+S1hcfqY6d36PrkveZB3SssbsK5/45f6T1crMbc+FM33KbcHjOFm+/Mpl95y1Gy3ogn1DTmHVTrO5wHmA181P3qgebR/P8no8vmIvZ6k1lN5CsiYg+bIxmvPefArGZvKC8zi7iRLQWjXIovonu/uT8U6vfNjLNozdGP5HP0tAAA+wJNAQCQ0BQAAAlNAQCQ0BQAAMm8Tx+tXqHHCKxa8xJZ/x9/o4/f8p28doAZ0bDLjVdwwRRRa5t27TYxebyj68cfqetqQx23V0ttkia1SULV5nnK51+a7ihIfRRt9hMRrzjfPaaL2uQns+bSJ+SRK9fq99uuh8zS5nXTZ2E23zHJO3fRu12RBhr8qe+ZGPOxYo0eE7PmI3pMTCwsPJeycGCZko/T7vfepab2Mb4pAAASmgIAIKEpAAASmgIAIKEpAACSeZ8+cr71v3TKaMwkHA54tSi6ZIbZyONBkWCKiDhWrO1my4wdrOunnqbrjXmF778jr534Jn3sqPno0Li6SVWoTW9sAsOsXbJBjhtD1Ono+sVXHirr1176uKyfIjbfOfQ8vfa1/0G/31b8yeGy3mrnUbDGxcAKP9v1+/oN2hUbG7ngldkzKA43Ca6qNZEXax3TO+XX9Br3f0vXw83Pmk3mvaV+J0rnRO1rfFMAACQ0BQBAQlMAACQ0BQBAQlMAACQjMzMzA+1FNDIyMtvnMiec+G5df2xTXttpZhxFx9Qf1eWzLxPFwtkyLiUyZc6lEqmkTRv0sc/cp+snullBhvoEohJJEX5+kqMSTy4F9fgDuv5y83wONjvPqefzw0362Mv/7TGyXtsYi6qX7aTmjp+c0mmq7WoOk1n6m1fr+hv/QNfHxTV071n30t/6cfODWbT0wsJ/MISP2etv3fs1nEH+3PNNAQCQ0BQAAAlNAQCQ0BQAAAlNAQCQ/MLOPrJKdk0r3X3KKVjHzv4xa0yY41Uq6ehXmbWP1eX7bjHHF1jiZuWY+VEurRRD2MVqwuw8516e7R1RXK+Prd2woIJd3Rz3ya6ue7I+5WYFDeGvwY7v6/qken3MidemvvSCsuPvv00U9XirWPY6XXfzs4bxcdq9Jfa1OXpaAIB9gaYAAEhoCgCAhKYAAEi40fzPTOt7c9FXN5zc1TPjLM5bpevqVqPbwMYy512Zm6cLxGY9/Y4+9p4bCs+lwEYzWmPGXMOhOEmX7ciNtq4/bW6GS+aGsruRKV/+smkW0ek+Keu9abOMWOcuM87CaQquoX2Lu5u75vetZe7VLxMjKuzGULN4Q9mdd3cI4YjZwDcFAEBCUwAAJDQFAEBCUwAAJDQFAEBC+uif2XLH3q/xxo/qutv0RY1oqAqOjdhDMMWtI9IWLgk0m1zK6Jgzdb0/aRYSKavH7zfHmjW2dAZfOyLkb88Bp5pjLRc/yhd3r/HU9A5Zn3zMPKJJ67RNyqqIuVZyTIxhE1mFqSR5uLuI7jU2GpPgUqMr3Hk/rMZwzAF8UwAAJDQFAEBCUwAAJDQFAEBCUwAAJKSPBrTyusWiqmMFG+59Qi/i5q6IeTGlo1iawrkw6vgn7zGL7wM/Muey2MwtKnonu0SWW8MkTWJBXnr/7x2jjzWRmqpykZ/8le5O691xtm/bKet9Nw/LvIm+/mlzKgW2btT1RUcOfh520yDzA/eyNWrekksqub2OClJGESHfW2521lzFNwUAQEJTAAAkNAUAQEJTAAAkNAUAQEL6aEB1nUeEtm9/Wh7rEg59HR6RUSObbnCxJFN3h9+11vxgjus8oOsyf/NSs8hTpv4SU39Gl1+8KK9V7nNWy2ZkZHWykw8umtzxnDy219Eru/fhN//WnMoQ/MTMm1p4tCgWRuzsr8TgAS7/mC5hVvoXUjxm7daeo/imAABIaAoAgISmAABIaAoAgISmAABIRmZmZmYGOnBkZLbPZf44XJdf/6u6Xk/kNbvzWsEOVns6/q7PF66zH7r8upfJeq8nhk1FxNjEcbLe7+sXoyUiYjYcZobrdKY2y/rk1l35eZgUi3vMMfOR747PmH8wmw7KS0vfYI4tTd6VzBYq3NFwGNb/3eytXWqQP/d8UwAAJDQFAEBCUwAAJDQFAEDCmIu98OSWR2R96p9ul/U3/OXlsv7I6rz26csulMfeFLfpk/kFvqHs9M0N5faY2PElIvpmV5rKzYsQF72u9Rrbtz0u652tZmX1eprXuGXqd1yr6/uEmEPypSu+Ig99zQfeLusnv0Yvve7Lur58RV5zI0HW3aLrp/+GrpuXeU7dVH6h+KYAAEhoCgCAhKYAAEhoCgCAhKYAAEgYczEHnH/u2Vntq3fetQ/OZH657ML8ukZEtN+hdzu6/aaHZf1HJplyydX578SOzfrXacP39RqHLdR15Qff0fWn7ht8jfnotk/9rqxf+OHB53nc82URAYyIX3/nKll/cuCV5xbGXAAAitAUAAAJTQEAkNAUAAAJTQEAkJA+An7mox/WKZbfOuNYWT/xnR/Mi4v12o/eqIfiHLX8goHODRgG0kcAgCI0BQBAQlMAACQ0BQBAQlMAACSkjwDgFwTpIwBAEZoCACChKQAAEpoCACChKQAAEpoCACChKQAAEpoCACChKQAAEpoCACChKQAAEpoCACChKQAAEpoCACChKQAAEpoCACBpDXrggHvxAAD2Y3xTAAAkNAUAQEJTAAAkNAUAQEJTAAAkNAUAQEJTAAAkNAUAQEJTAAAk/xeYwT3qZ0rRaQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Afficher la première image du lot\n",
    "plt.imshow(images[0])\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eugen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\eugen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6272</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">633,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6272</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,819</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6272\u001b[0m)           │       \u001b[38;5;34m633,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6272\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m262,272\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_transpose_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m262,272\u001b[0m │\n",
       "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │        \u001b[38;5;34m18,819\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,176,835</span> (4.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,176,835\u001b[0m (4.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,176,835</span> (4.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,176,835\u001b[0m (4.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Fonction pour construire le modèle générateur\n",
    "def build_generator(latent_dim):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(7*7*128, input_dim=latent_dim))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Reshape((7, 7, 128)))\n",
    "    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Conv2D(3, (7, 7), activation='tanh', padding='same'))  # Utilisation de l'activation tanh pour générer des valeurs entre -1 et 1\n",
    "    \n",
    "    # Compiler le modèle\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Dimension de l'espace latent\n",
    "latent_dim = 100\n",
    "\n",
    "# Construire le générateur\n",
    "generator = build_generator(latent_dim)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eugen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16384</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,385</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16384\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m16,385\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,105</span> (215.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m55,105\u001b[0m (215.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,105</span> (215.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m55,105\u001b[0m (215.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Fonction pour construire le modèle discriminateur\n",
    "def build_discriminator(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', input_shape=input_shape))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    model.add(layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compiler le modèle\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Taille des images\n",
    "input_shape = (64, 64, 3)\n",
    "\n",
    "# Construire le discriminateur\n",
    "discriminator = build_discriminator(input_shape)\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step \n",
      "Epoch 1, Batch 1/6, D Loss=0.7743316888809204, G Loss=[array(0.7487989, dtype=float32), array(0.7487989, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Epoch 1, Batch 2/6, D Loss=0.7488309741020203, G Loss=[array(0.7416202, dtype=float32), array(0.7416202, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Epoch 1, Batch 3/6, D Loss=0.7397645711898804, G Loss=[array(0.7342611, dtype=float32), array(0.7342611, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Epoch 1, Batch 4/6, D Loss=0.737429141998291, G Loss=[array(0.734647, dtype=float32), array(0.734647, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Epoch 1, Batch 5/6, D Loss=0.7383414506912231, G Loss=[array(0.7360586, dtype=float32), array(0.7360586, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Epoch 1, Batch 6/6, D Loss=0.736968994140625, G Loss=[array(0.73567915, dtype=float32), array(0.73567915, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Epoch 2, Batch 1/6, D Loss=0.7374193668365479, G Loss=[array(0.7359191, dtype=float32), array(0.7359191, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Epoch 2, Batch 2/6, D Loss=0.7381659746170044, G Loss=[array(0.73747635, dtype=float32), array(0.73747635, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Epoch 2, Batch 3/6, D Loss=0.7380995154380798, G Loss=[array(0.7374795, dtype=float32), array(0.7374795, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Epoch 2, Batch 4/6, D Loss=0.7401936054229736, G Loss=[array(0.739817, dtype=float32), array(0.739817, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Epoch 2, Batch 5/6, D Loss=0.7405186891555786, G Loss=[array(0.7401189, dtype=float32), array(0.7401189, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Epoch 2, Batch 6/6, D Loss=0.7423951625823975, G Loss=[array(0.74215484, dtype=float32), array(0.74215484, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Epoch 3, Batch 1/6, D Loss=0.7443087100982666, G Loss=[array(0.74417114, dtype=float32), array(0.74417114, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Epoch 3, Batch 2/6, D Loss=0.744870662689209, G Loss=[array(0.745039, dtype=float32), array(0.745039, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Epoch 3, Batch 3/6, D Loss=0.747746467590332, G Loss=[array(0.74825054, dtype=float32), array(0.74825054, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Epoch 3, Batch 4/6, D Loss=0.7497954368591309, G Loss=[array(0.7501611, dtype=float32), array(0.7501611, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Epoch 3, Batch 5/6, D Loss=0.7508793473243713, G Loss=[array(0.7509917, dtype=float32), array(0.7509917, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Epoch 3, Batch 6/6, D Loss=0.7530099153518677, G Loss=[array(0.7536135, dtype=float32), array(0.7536135, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Epoch 4, Batch 1/6, D Loss=0.7562024593353271, G Loss=[array(0.7568345, dtype=float32), array(0.7568345, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step \n",
      "Epoch 4, Batch 2/6, D Loss=0.7587218284606934, G Loss=[array(0.75949556, dtype=float32), array(0.75949556, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Epoch 4, Batch 3/6, D Loss=0.7611813545227051, G Loss=[array(0.76185966, dtype=float32), array(0.76185966, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Epoch 4, Batch 4/6, D Loss=0.763582706451416, G Loss=[array(0.7643252, dtype=float32), array(0.7643252, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Epoch 4, Batch 5/6, D Loss=0.7653098106384277, G Loss=[array(0.7659834, dtype=float32), array(0.7659834, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Epoch 4, Batch 6/6, D Loss=0.7676883935928345, G Loss=[array(0.76849484, dtype=float32), array(0.76849484, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Epoch 5, Batch 1/6, D Loss=0.7699459195137024, G Loss=[array(0.7709475, dtype=float32), array(0.7709475, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Epoch 5, Batch 2/6, D Loss=0.7724121809005737, G Loss=[array(0.77333015, dtype=float32), array(0.77333015, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Epoch 5, Batch 3/6, D Loss=0.774316668510437, G Loss=[array(0.77524984, dtype=float32), array(0.77524984, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Epoch 5, Batch 4/6, D Loss=0.7767302989959717, G Loss=[array(0.77773285, dtype=float32), array(0.77773285, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Epoch 5, Batch 5/6, D Loss=0.7786343097686768, G Loss=[array(0.779611, dtype=float32), array(0.779611, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Epoch 5, Batch 6/6, D Loss=0.780349850654602, G Loss=[array(0.7813683, dtype=float32), array(0.7813683, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Epoch 6, Batch 1/6, D Loss=0.7822821736335754, G Loss=[array(0.78331155, dtype=float32), array(0.78331155, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Epoch 6, Batch 2/6, D Loss=0.7846341133117676, G Loss=[array(0.7856406, dtype=float32), array(0.7856406, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Epoch 6, Batch 3/6, D Loss=0.7869178652763367, G Loss=[array(0.7881369, dtype=float32), array(0.7881369, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Epoch 6, Batch 4/6, D Loss=0.7889692783355713, G Loss=[array(0.79023886, dtype=float32), array(0.79023886, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Epoch 6, Batch 5/6, D Loss=0.7915455102920532, G Loss=[array(0.79265493, dtype=float32), array(0.79265493, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Epoch 6, Batch 6/6, D Loss=0.7936097979545593, G Loss=[array(0.7948602, dtype=float32), array(0.7948602, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Epoch 7, Batch 1/6, D Loss=0.7958455085754395, G Loss=[array(0.79691064, dtype=float32), array(0.79691064, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step \n",
      "Epoch 7, Batch 2/6, D Loss=0.7986109256744385, G Loss=[array(0.79992276, dtype=float32), array(0.79992276, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "Epoch 7, Batch 3/6, D Loss=0.8008971214294434, G Loss=[array(0.80209035, dtype=float32), array(0.80209035, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Epoch 7, Batch 4/6, D Loss=0.8030778169631958, G Loss=[array(0.8044256, dtype=float32), array(0.8044256, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Epoch 7, Batch 5/6, D Loss=0.8056461811065674, G Loss=[array(0.80714047, dtype=float32), array(0.80714047, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Epoch 7, Batch 6/6, D Loss=0.8084656000137329, G Loss=[array(0.8100882, dtype=float32), array(0.8100882, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Epoch 8, Batch 1/6, D Loss=0.8113176226615906, G Loss=[array(0.81290203, dtype=float32), array(0.81290203, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Epoch 8, Batch 2/6, D Loss=0.8143945932388306, G Loss=[array(0.81607175, dtype=float32), array(0.81607175, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Epoch 8, Batch 3/6, D Loss=0.8178527355194092, G Loss=[array(0.8197626, dtype=float32), array(0.8197626, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Epoch 8, Batch 4/6, D Loss=0.82137131690979, G Loss=[array(0.8234371, dtype=float32), array(0.8234371, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Epoch 8, Batch 5/6, D Loss=0.8250348567962646, G Loss=[array(0.82691514, dtype=float32), array(0.82691514, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Epoch 8, Batch 6/6, D Loss=0.8281823396682739, G Loss=[array(0.8301546, dtype=float32), array(0.8301546, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Epoch 9, Batch 1/6, D Loss=0.8320934176445007, G Loss=[array(0.83436424, dtype=float32), array(0.83436424, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Epoch 9, Batch 2/6, D Loss=0.8363863229751587, G Loss=[array(0.8388495, dtype=float32), array(0.8388495, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Epoch 9, Batch 3/6, D Loss=0.8406131863594055, G Loss=[array(0.8431074, dtype=float32), array(0.8431074, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Epoch 9, Batch 4/6, D Loss=0.8452602624893188, G Loss=[array(0.8479305, dtype=float32), array(0.8479305, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Epoch 9, Batch 5/6, D Loss=0.8500889539718628, G Loss=[array(0.8527544, dtype=float32), array(0.8527544, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Epoch 9, Batch 6/6, D Loss=0.8551032543182373, G Loss=[array(0.858022, dtype=float32), array(0.858022, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Epoch 10, Batch 1/6, D Loss=0.8604369163513184, G Loss=[array(0.863429, dtype=float32), array(0.863429, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Epoch 10, Batch 2/6, D Loss=0.8659039735794067, G Loss=[array(0.8691279, dtype=float32), array(0.8691279, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Epoch 10, Batch 3/6, D Loss=0.871903657913208, G Loss=[array(0.87519556, dtype=float32), array(0.87519556, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Epoch 10, Batch 4/6, D Loss=0.8779275417327881, G Loss=[array(0.8813974, dtype=float32), array(0.8813974, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Epoch 10, Batch 5/6, D Loss=0.8843685388565063, G Loss=[array(0.8879373, dtype=float32), array(0.8879373, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Epoch 10, Batch 6/6, D Loss=0.8909677267074585, G Loss=[array(0.8947268, dtype=float32), array(0.8947268, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Epoch 11, Batch 1/6, D Loss=0.897322952747345, G Loss=[array(0.90090185, dtype=float32), array(0.90090185, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Epoch 11, Batch 2/6, D Loss=0.9037542343139648, G Loss=[array(0.9076509, dtype=float32), array(0.9076509, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Epoch 11, Batch 3/6, D Loss=0.9108492136001587, G Loss=[array(0.91494495, dtype=float32), array(0.91494495, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Epoch 11, Batch 4/6, D Loss=0.9182056188583374, G Loss=[array(0.92245746, dtype=float32), array(0.92245746, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Epoch 11, Batch 5/6, D Loss=0.9258284568786621, G Loss=[array(0.9302641, dtype=float32), array(0.9302641, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Epoch 11, Batch 6/6, D Loss=0.9335447549819946, G Loss=[array(0.93804616, dtype=float32), array(0.93804616, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Epoch 12, Batch 1/6, D Loss=0.9414830803871155, G Loss=[array(0.94614726, dtype=float32), array(0.94614726, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Epoch 12, Batch 2/6, D Loss=0.9500312805175781, G Loss=[array(0.954914, dtype=float32), array(0.954914, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Epoch 12, Batch 3/6, D Loss=0.9583039879798889, G Loss=[array(0.9629765, dtype=float32), array(0.9629765, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Epoch 12, Batch 4/6, D Loss=0.9667580127716064, G Loss=[array(0.9717283, dtype=float32), array(0.9717283, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Epoch 12, Batch 5/6, D Loss=0.9751758575439453, G Loss=[array(0.98011553, dtype=float32), array(0.98011553, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Epoch 12, Batch 6/6, D Loss=0.9837819337844849, G Loss=[array(0.9887536, dtype=float32), array(0.9887536, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Epoch 13, Batch 1/6, D Loss=0.9927114248275757, G Loss=[array(0.99785334, dtype=float32), array(0.99785334, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Epoch 13, Batch 2/6, D Loss=1.0019265413284302, G Loss=[array(1.0073123, dtype=float32), array(1.0073123, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Epoch 13, Batch 3/6, D Loss=1.0111134052276611, G Loss=[array(1.0164883, dtype=float32), array(1.0164883, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Epoch 13, Batch 4/6, D Loss=1.0201733112335205, G Loss=[array(1.0254189, dtype=float32), array(1.0254189, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "Epoch 13, Batch 5/6, D Loss=1.029437780380249, G Loss=[array(1.0350678, dtype=float32), array(1.0350678, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Epoch 13, Batch 6/6, D Loss=1.0387433767318726, G Loss=[array(1.0441178, dtype=float32), array(1.0441178, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Epoch 14, Batch 1/6, D Loss=1.0480611324310303, G Loss=[array(1.0536436, dtype=float32), array(1.0536436, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "Epoch 14, Batch 2/6, D Loss=1.0576022863388062, G Loss=[array(1.0631295, dtype=float32), array(1.0631295, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Epoch 14, Batch 3/6, D Loss=1.0669004917144775, G Loss=[array(1.072451, dtype=float32), array(1.072451, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Epoch 14, Batch 4/6, D Loss=1.0763275623321533, G Loss=[array(1.0820639, dtype=float32), array(1.0820639, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Epoch 14, Batch 5/6, D Loss=1.0858769416809082, G Loss=[array(1.091494, dtype=float32), array(1.091494, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step \n",
      "Epoch 14, Batch 6/6, D Loss=1.095495581626892, G Loss=[array(1.1012368, dtype=float32), array(1.1012368, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "Epoch 15, Batch 1/6, D Loss=1.1054130792617798, G Loss=[array(1.1112902, dtype=float32), array(1.1112902, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Epoch 15, Batch 2/6, D Loss=1.1149730682373047, G Loss=[array(1.1205499, dtype=float32), array(1.1205499, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Epoch 15, Batch 3/6, D Loss=1.1244471073150635, G Loss=[array(1.130315, dtype=float32), array(1.130315, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Epoch 15, Batch 4/6, D Loss=1.1339434385299683, G Loss=[array(1.1395447, dtype=float32), array(1.1395447, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Epoch 15, Batch 5/6, D Loss=1.1432740688323975, G Loss=[array(1.1490158, dtype=float32), array(1.1490158, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Epoch 15, Batch 6/6, D Loss=1.1528682708740234, G Loss=[array(1.1586697, dtype=float32), array(1.1586697, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Epoch 16, Batch 1/6, D Loss=1.162346363067627, G Loss=[array(1.168129, dtype=float32), array(1.168129, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Epoch 16, Batch 2/6, D Loss=1.1716668605804443, G Loss=[array(1.1774117, dtype=float32), array(1.1774117, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Epoch 16, Batch 3/6, D Loss=1.1812546253204346, G Loss=[array(1.1871295, dtype=float32), array(1.1871295, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Epoch 16, Batch 4/6, D Loss=1.1907095909118652, G Loss=[array(1.1964511, dtype=float32), array(1.1964511, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Epoch 16, Batch 5/6, D Loss=1.20010244846344, G Loss=[array(1.2059538, dtype=float32), array(1.2059538, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Epoch 16, Batch 6/6, D Loss=1.209362268447876, G Loss=[array(1.2150928, dtype=float32), array(1.2150928, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Epoch 17, Batch 1/6, D Loss=1.2189316749572754, G Loss=[array(1.2248714, dtype=float32), array(1.2248714, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Epoch 17, Batch 2/6, D Loss=1.2285358905792236, G Loss=[array(1.2343968, dtype=float32), array(1.2343968, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Epoch 17, Batch 3/6, D Loss=1.2376803159713745, G Loss=[array(1.2432942, dtype=float32), array(1.2432942, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Epoch 17, Batch 4/6, D Loss=1.2468080520629883, G Loss=[array(1.2526767, dtype=float32), array(1.2526767, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Epoch 17, Batch 5/6, D Loss=1.25628662109375, G Loss=[array(1.2621319, dtype=float32), array(1.2621319, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step \n",
      "Epoch 17, Batch 6/6, D Loss=1.2655431032180786, G Loss=[array(1.2713531, dtype=float32), array(1.2713531, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "Epoch 18, Batch 1/6, D Loss=1.2747721672058105, G Loss=[array(1.2805282, dtype=float32), array(1.2805282, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Epoch 18, Batch 2/6, D Loss=1.2839579582214355, G Loss=[array(1.2897191, dtype=float32), array(1.2897191, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "Epoch 18, Batch 3/6, D Loss=1.2930402755737305, G Loss=[array(1.2987503, dtype=float32), array(1.2987503, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Epoch 18, Batch 4/6, D Loss=1.302241325378418, G Loss=[array(1.3080144, dtype=float32), array(1.3080144, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Epoch 18, Batch 5/6, D Loss=1.3114736080169678, G Loss=[array(1.3173271, dtype=float32), array(1.3173271, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Epoch 18, Batch 6/6, D Loss=1.320671796798706, G Loss=[array(1.326501, dtype=float32), array(1.326501, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Epoch 19, Batch 1/6, D Loss=1.3297019004821777, G Loss=[array(1.3353932, dtype=float32), array(1.3353932, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Epoch 19, Batch 2/6, D Loss=1.338587760925293, G Loss=[array(1.3442196, dtype=float32), array(1.3442196, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Epoch 19, Batch 3/6, D Loss=1.34738290309906, G Loss=[array(1.3529887, dtype=float32), array(1.3529887, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Epoch 19, Batch 4/6, D Loss=1.355980396270752, G Loss=[array(1.3615574, dtype=float32), array(1.3615574, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Epoch 19, Batch 5/6, D Loss=1.36458420753479, G Loss=[array(1.3702765, dtype=float32), array(1.3702765, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Epoch 19, Batch 6/6, D Loss=1.3734291791915894, G Loss=[array(1.3790908, dtype=float32), array(1.3790908, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Epoch 20, Batch 1/6, D Loss=1.3820958137512207, G Loss=[array(1.3877122, dtype=float32), array(1.3877122, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Epoch 20, Batch 2/6, D Loss=1.3907382488250732, G Loss=[array(1.3964208, dtype=float32), array(1.3964208, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Epoch 20, Batch 3/6, D Loss=1.3994779586791992, G Loss=[array(1.405194, dtype=float32), array(1.405194, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Epoch 20, Batch 4/6, D Loss=1.4082067012786865, G Loss=[array(1.4138716, dtype=float32), array(1.4138716, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Epoch 20, Batch 5/6, D Loss=1.4168057441711426, G Loss=[array(1.4223703, dtype=float32), array(1.4223703, dtype=float32)]\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Epoch 20, Batch 6/6, D Loss=1.4251821041107178, G Loss=[array(1.4306929, dtype=float32), array(1.4306929, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Fonction pour construire le modèle GAN\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    gan_input = layers.Input(shape=(latent_dim,))\n",
    "    gan_output = discriminator(generator(gan_input))\n",
    "    gan_model = models.Model(gan_input, gan_output)\n",
    "    gan_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return gan_model\n",
    "\n",
    "# Fonction pour générer des exemples de données aléatoires\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    x_input = np.random.randn(n_samples, latent_dim)\n",
    "    return x_input\n",
    "\n",
    "# Fonction pour l'entraînement du GAN\n",
    "def train_gan(generator, discriminator, gan_model, latent_dim, X_real, n_epochs=20, batch_size=128):\n",
    "    half_batch = int(batch_size / 2)\n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(len(X_real) // batch_size):\n",
    "            # Sélection d'un sous-ensemble aléatoire des images réelles\n",
    "            ix = np.random.randint(0, X_real.shape[0], half_batch)\n",
    "            X_real_batch = X_real[ix]\n",
    "            # Génération des exemples de données latentes aléatoires\n",
    "            X_fake_batch = generate_latent_points(latent_dim, half_batch)\n",
    "            # Génération des exemples de données Pokémon synthétiques\n",
    "            X_fake_batch = generator.predict(X_fake_batch)\n",
    "            # Création des étiquettes pour les données réelles et synthétiques\n",
    "            y_real = np.ones((half_batch, 1))\n",
    "            y_fake = np.zeros((half_batch, 1))\n",
    "            # Entraînement du discriminateur sur les données réelles\n",
    "            d_loss_real = discriminator.train_on_batch(X_real_batch, y_real)\n",
    "            # Entraînement du discriminateur sur les données synthétiques\n",
    "            d_loss_fake = discriminator.train_on_batch(X_fake_batch, y_fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            # Préparation des points de données latentes comme entrée pour le GAN\n",
    "            X_gan = generate_latent_points(latent_dim, batch_size)\n",
    "            # Création des étiquettes trompeuses pour les données générées par le générateur\n",
    "            y_gan = np.ones((batch_size, 1))\n",
    "            # Entraînement du générateur via le modèle GAN\n",
    "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "            # Affichage de la progression de l'entraînement\n",
    "            print(f\"Epoch {epoch + 1}, Batch {i + 1}/{len(X_real) // batch_size}, D Loss={d_loss}, G Loss={g_loss}\")\n",
    "\n",
    "# Paramètres du modèle GAN\n",
    "latent_dim = 100\n",
    "\n",
    "# Chargement des données réelles\n",
    "# Remplacez cette fonction par votre propre méthode de chargement des données réelles\n",
    "def load_real_samples():\n",
    "    return images\n",
    "\n",
    "# Construction du générateur\n",
    "def build_generator(latent_dim):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(128 * 8 * 8, input_dim=latent_dim))\n",
    "    model.add(layers.Reshape((8, 8, 128)))\n",
    "    model.add(layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Construction du discriminateur\n",
    "def build_discriminator(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(64, (3,3), strides=(2,2), padding='same', input_shape=input_shape))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    model.add(layers.Conv2D(64, (3,3), strides=(2,2), padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Paramètres d'entraînement\n",
    "n_epochs = 20\n",
    "batch_size = 128\n",
    "\n",
    "# Chargement des données réelles\n",
    "images = load_real_samples()\n",
    "\n",
    "# Taille des images\n",
    "input_shape = images.shape[1:]\n",
    "\n",
    "# Compilation du modèle du discriminateur\n",
    "discriminator = build_discriminator(input_shape)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# Construction du modèle GAN\n",
    "generator = build_generator(latent_dim)\n",
    "gan_model = build_gan(generator, discriminator)\n",
    "\n",
    "# Entraînement du modèle GAN\n",
    "train_gan(generator, discriminator, gan_model, latent_dim, images, n_epochs=n_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Définir une fonction pour générer une image aléatoire de Pokémon avec uniquement ses contours\n",
    "def generate_random_pokemon_contours(generator, latent_dim):\n",
    "    # Générer un bruit aléatoire\n",
    "    noise = np.random.normal(0, 1, (1, latent_dim))\n",
    "    # Utiliser le générateur pour produire une image\n",
    "    generated_image = generator.predict(noise)\n",
    "    # Mettre à l'échelle les valeurs des pixels entre 0 et 255\n",
    "    generated_image = ((generated_image + 1) / 2.0 * 255).astype(np.uint8)\n",
    "    # Convertir l'image en échelle de gris\n",
    "    grayscale_image = cv2.cvtColor(generated_image[0], cv2.COLOR_RGB2GRAY)\n",
    "    # Appliquer un filtre de détection de contours avec des paramètres ajustés\n",
    "    edges = cv2.Canny(grayscale_image, 50, 150)  # Ajuster les seuils pour un meilleur résultat\n",
    "    # Créer une image vide pour afficher les contours\n",
    "    contour_image = np.zeros_like(generated_image[0])\n",
    "    # Dessiner les contours sur l'image vide\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(contour_image, contours, -1, (255, 255, 255), 1)\n",
    "    # Afficher l'image résultante avec uniquement les contours\n",
    "    plt.imshow(contour_image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Utiliser la fonction pour générer une image aléatoire de Pokémon avec uniquement ses contours\n",
    "generate_random_pokemon_contours(generator, latent_dim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
